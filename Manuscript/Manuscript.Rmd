---
title             : "Domain-specific working memory loads selectively increase negative interpretations of surprised facial expressions"
shorttitle        : "DOMAIN-SPECIFIC WORKING MEMORY AND SURPRISED EXPRESSIONS"

author: 
  - name          : "Nicholas R. Harp"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "nharp@huskers.unl.edu"
  - name          : "Maital Neta"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Nebraska-Lincoln"

authornote: |
  Nicholas R. Harp, Department of Psychology, Center for Brain, Biology, and Behavior, University of Nebraska-Lincoln
  Maital Neta, Department of Psychology, Center for Brain, Biology, and Behavior, University of Nebraska-Lincoln

abstract: |
  Individual differences in interpretations of emotional ambiguity are a useful tool for measuring affective biases. 
  
  While trait-like, these biases are also susceptible to experimental manipulations. In the present study, we capitalize on this malleability to expand on previous research suggesting that
  subjective interpretations are stable independently of cognitive load. 
  
  We tested the effects of working memory loads containing either neutral or emotional content on concurrent interpretations of surprised facial expressions.
  
  Here we show that interpretations of surprise are more negative during maintenance of working memory loads with emotional content compared to those with neutral content.
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "ambiguity, working memory, bias"
wordcount         : "X"

bibliography      : ["CANLab_UNL.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_word
---

```{r setup, include = FALSE}
library("papaja")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
### import z score updated function ###
source("~/Documents/Nick-Grad/Neta_Lab/depletion_study/study2/Analyses/WorkingMemoryLoads/wilcox_test.R")
### code edits taken from : https://stats.stackexchange.com/questions/306841/z-score-on-wilcoxon-signed-ranks-test ###

### load necessary libraries ###
suppressPackageStartupMessages(library(readxl)) 
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(openxlsx))
suppressPackageStartupMessages(library(Rmisc))
suppressPackageStartupMessages(library(broom))
```
# Introduction
## Facial expressions and individual differences

### Facial expressions are an important social signal
Facial expressions are important social signals, often communicating emotion between individuals and even sparking emotional responses in the perceiver [@frith_role_2009]. Researchers have long argued that facial expressions are universal signals of emotion, positing humans' innate ability to associate facial expressions with emotional experience [@darwin_expression_1872; @ekman_constants_1971; @izard_innate_1994]. More recently, Barrett and colleagues suggested that the relationship between facial expressions and emotions is more complex, stating that expression of an emotion may vary across cultures, social context, or even individuals -[@barrett_emotional_2019]. Other work has shown individual differences in interpretations of facial expressions [@green_factors_2018; @neta_corrugator_2009]. Regardless of this variability in emotional expressions, experience, and interpretations, humans readily make judgments about personality traits (e.g., trustworthiness), aesthetics (e.g., attractiveness), and emotions from faces [@todorov_evaluating_2008; @said_statistical_2011; @carroll_facil_1996]. Interpretations of valence, that is the inherent positive or negative emotional value of a stimulus, are one instance of judgments of facial expressions guiding potential social (i.e., approach-avoidance) behavior <!-- not sure if this is truly social? --> [@krieglmeyer_being_2010]. 

### Individuals differ (trait) in their tendency to interpret ambiguous images, like a surprised face
While most people can accurately differentiate the emotional valence of many facial expressions [CITE], such as consistently interpreting angry (happy) faces as negative (positive), there are individual differences in valence judgments of emotionally ambiguous facial expressions, like a surprised face [@neta_corrugator_2009; @petro_individual_2018 <!-- right citations?-->]. This difference in valence interpretations of surprised expressions is attributable to such stimuli's predictive value for both positive and negative outcomes in an individual's previous experience. For instance, a surprised expression could signal positive (e.g., winning the lottery) or negative (e.g., a car accident) events. These differences in valence interpretations represent an important individual difference, as the same stimulus can result in two alternative interpretations between individuals--likely leading to different downstream behaviors [e.g., @krieglmeyer_being_2010]. This individual difference in interpretations of emotionally ambiguous stimuli is known as one's *valence bias*, and a growing body of work has used both facial expressions and scenes to better understand this individual difference [@neta_corrugator_2009; @neta_primacy_2010; @neta_neural_2013]. 

### Despite the bias, everyone seems to show an initial negativity--positivity is associated with emotion regulation
Despite one's valence bias, the initial response to ambiguity appears to be negativity [@neta_corrugator_2009; @neta_primacy_2010; @neta_valence_2011; @petro_individual_2018]. Under this framework, which is known as the *initial negativity* hypothesis, positive interpretations rely on the implementation of some emotion regulation strategy, perhaps similar to cognitive reappraisal. During cognitive reappraisal, individuals work to change intial perceptions of an emotional stimulus [@lazarus_short_1964]. Similarly, the initial negativity hypothesis posits that individuals' initial perception of surprised expressions is negative, and that those arriving at a positive interpretation must implement a regulatory mechanism to alter their interpretation. 

### Behavioral and brain data supports the initial negativity hypothesis
Both behavioral and brain data in support of the initial negativity hypothesis come from many studies. For instance, reaction time (RT) data show that individuals with more positive biases take longer to reach a valence judgment for surprised expressions than those with a more negative bias [@neta_corrugator_2009], suggesting a more time-intensive (regulatory) process for positive interpretations. Other work demonstrates the automaticity of negative interpretations through presenting either low- (LSF) or high-spatial frequency (HSF) images of surprised expressions. The images with only LSF information, which is processed earlier than its HSF counterpart, were rated more negatively than the HSF images [@neta_primacy_2010]. Additionally, surprised facial expressions are more quickly detected among happy (positive) than angry (negative) faces [@neta_valence_2011]. The results from this emotional oddball paradigm suggest that surprised expressions are more readily perceived as similar to angry faces (i.e., perceived as negative) than happy faces. There is also support for the initial negativity hypothesis in studies with brain data. Ventromedial prefrontal cortex, a putative regulatory region, and the amygdala actively are inversely correlated, and participants with more negative biases show higher activity in the amygdala while more positive participants show higher activity in vmPFC [@kim_inverse_2003]. More recently, Petro and colleagues showed that participants with a more positive valence bias show more activity for surprised faces in emotion regulation-related brain regions -[vmPFC; @petro_individual_2018].Taken together, these effects support the idea that negative interpretations of surprised faces are faster and default process, while positive interpretations rely on slower regulatory processes. <!-- is it okay to combine these sections? -->

## Cognitive loads and task interference
### In our daily lives, these resources are not always available


### Active WM maintenance affects concurrent processes

### Other work has tested the effects of cognitive load on valence bias, but did not find an effect for interpretations of surprise. This could be due to domain-specific effects of cognitive load. 

## The present study

### h1: domain main effect

### h2: domain x load interaction


# Methods
## Participants
``` {r read data}
data <- read.csv("~/Documents/Nick-Grad/Neta_Lab/depletion_study/study2/Analyses/WorkingMemoryLoads/Data/Cleaned_Data/Final.Data.csv_2019-09-06_12-18-56.csv")
```
Fifty-eight subjects were recruited from the undergraduate research pool at the University of Nebraska-Lincoln. The data from eight subjects were excluded due to technical difficulties resulting from an error in one of the experiment scripts. This left 50 individuals in the final sample for analysis. The mean age of the remaining sample was `r printnum(mean(data$age))` (`r printnum(sd(data$age))`), a majority of participants were female (`r printnum((sum(data$sex == "Female") / nrow(data))*100)`%), and all were white/caucasian without hispanic/Latinx ethnicity. All subjects provided written informed consent in accordance with the Declaration of Helsinki and all procedures were approved by the University of Nebraska-Lincoln Institutional Review Board (Approval #20141014670EP). Each participant received course credit for completing the study. 

## Material
### Stimuli
``` {r stimulus_t.test, include = FALSE}
stim.data <- read.xlsx("~/Documents/Nick-Grad/Neta_Lab/depletion_study/study2/Analyses/WorkingMemoryLoads/IAPS_Stim_List.xlsx")
shapiro.test(subset(stim.data, Condition == "POS")$Aro_Mn)
shapiro.test(subset(stim.data, Condition == "NEG")$Aro_Mn)
stim.t.test <- wilcox_test(subset(stim.data, Condition == "POS")$Aro_Mn, subset(stim.data, Condition == "NEG")$Aro_Mn)
```
The stimuli included faces from the NimStim [@tottenham_nimstim_2009] and Karolinska Directed Emotional Faces [@lundqvist_karolinska_1998] stimuli sets, as in previous work [@neta_primacy_2010; @brown_cortisol_2017]. The faces consisted of 34 unique identities including 11 angry, 12 happy, and 24 surprised expressions organized pseudorandomly. The scene stimuli were selected from the International Affective Picture System [@lang_international_2008]. A total of 288 scenes (72 positive, 72 negative, and 144 neutral) were selected for the image matrices. The positive and negative images did not differ on arousal (Z = `r printnum(stim.t.test$z_val)`, p = `r printnum(stim.t.test$p.value)`). The scenes were organized into low (two images) and high (six images) cognitive load of either neutral or emotional (equal number of positive and negative) images (Figure 1). 

## Procedure
After arriving at the lab, participants provided informed consent prior to completing the task. Participants were randomly assigned to complete one of the task versions, which included 144 [^1] trials split between working memory probe and face rating trials. The task was completed using MouseTracker software [@freeman_mousetracker:_2010] and participants responded with a mouse to indicate the appropriate response for the face ratings (i.e., "POSITIVE" or "NEGATIVE") and the memory probe (i.e., "YES" or "NO"). The trials were self-initiated; that is, the participant clicked a "start" button at the bottom of the screen at the beginning of each trial at their own pace. After initiating the trial, a fixation cross appeared (1000 ms), then participants viewed an image matrix, which the participants were instructed to remember for the duration of the trial. The image matrix was presented for 4000 ms and the image was either a low or high load matrix consisting of either emotional (equal positive and negative) or neutral images. After the image matrix a happy, angry, or surprised face appeared for 1000 ms and the participants rated the face by clicking on either the positive or negative response option. After the face rating, a single image probe appeared (5000 ms), and participants indicated whether or not the image probe was present in the previous image matrix. 

[^1]: Some versions of the task only included 142 trials due to a programming error. 

## Data analysis
We used `r cite_r("r-references.bib")` for all our analyses. Data preprocessing was completed in R using the mousetrap package [@kieslich_mouse-tracking_inpress]. First, percent negative ratings were calculated for happy, angry, and surprised faces across all trial types, as well as a percent correct score for the memory probe trials. After, trials were screened for RT outliers. Any trials that were greater than three standard deviations from the mean were removed from the analyses. Additionally, we removed the preceding face rating trial for any incorrect memory probe trials, as these trials can be considered a manipulation failure. 

Prior to completing the analyses, all data were assessed for normality using Shapiro-Wilks tests. We tested for differences in valence bias among the different working memory load conditions. Friedman's test was used to assess overall differences and pairwise comparisons were completed using Wilcoxon signed rank tests using Bonferroni correction. Next, we tested for differences among maximum deviations in each working memory load condition using a load (low, high) X domain (emotional, neutral) repeated-measures ANOVA.

# Results
## Subjective ratings
```{r import data and analyze ratings, include = FALSE, echo = TRUE}

### remove psych disorders ### Ask maital?
# data <- data[-c(4, 33, 37, 38, 41, 47),]

### assess normality ###
shapiro.test(data$lo.neu.sur_rate) # non-normal
shapiro.test(data$hi.neu.sur_rate) # non-normal
shapiro.test(data$lo.emo.sur_rate) # non-normal
shapiro.test(data$hi.emo.sur_rate) # non-normal

### make data long ###
friedman.data <- gather(data, key = "Condition", value = "Percent Negative Ratings",
       lo.neu.sur_rate, hi.neu.sur_rate, lo.emo.sur_rate, hi.emo.sur_rate)

### run Friedman's test and store results ###
friedman.results <- friedman.test(`Percent Negative Ratings` ~ Condition|subjID, data = friedman.data)

### Follow up wilcoxon tests ###
lo.emo.v.lo.neu <- wilcox_test(data$lo.emo.sur_rate, data$lo.neu.sur_rate, paired = TRUE, conf.int = TRUE)
lo.emo.v.hi.neu <- wilcox_test(data$lo.emo.sur_rate, data$hi.neu.sur_rate, paired = TRUE, conf.int = TRUE)
lo.emo.v.hi.emo <- wilcox_test(data$lo.emo.sur_rate, data$hi.emo.sur_rate, paired = TRUE, conf.int = TRUE)
hi.emo.v.lo.neu <- wilcox_test(data$hi.emo.sur_rate, data$lo.neu.sur_rate, paired = TRUE, conf.int = TRUE)
hi.emo.v.hi.neu <- wilcox_test(data$hi.emo.sur_rate, data$hi.neu.sur_rate, paired = TRUE, conf.int = TRUE)
lo.neu.v.hi.neu <- wilcox_test(data$hi.neu.sur_rate, data$lo.neu.sur_rate, paired = TRUE, conf.int = TRUE)

### same results with ANOVA ###

# aov.data <- friedman.data
# aov.data$load <- recode(aov.data$Condition, "lo.neu.sur_rate" = "low",
#                         "hi.neu.sur_rate"= "high",
#                         "lo.emo.sur_rate"= "low",
#                         "hi.emo.sur_rate"= "high")
# aov.data$type <- recode(aov.data$Condition, "lo.neu.sur_rate" = "neu",
#                         "hi.neu.sur_rate"= "neu",
#                         "lo.emo.sur_rate"= "emo",
#                         "hi.emo.sur_rate"= "emo")
# summary(aov(`Percent Negative Ratings` ~ load * type, data = aov.data))
```
Distributions of ratings were first tested for normality using Shapiro-Wilk's test. The results of all four tests were highly significant (p's < .001), so non-parametric tests were used for data analysis. Friedman's test results showed significantly different rank-order distributions across the conditions $\chi^{2}$(`r (printnum(friedman.results$parameter))`) = `r printnum(friedman.results$statistic)`, p `r printp(friedman.results$p.value)`. Follow up Wilcoxon signed rank tests revealed that surprise is rated as more negative when holding emotional content in working memory compared to neutral content, and this was true for both low and high loads. Low emotional load ratings were significantly more negative than low, Z = `r (printnum(lo.emo.v.lo.neu$z_val))`, p = `r (printp(lo.emo.v.lo.neu$p.value))`, neutral and high, Z = `r (printnum(lo.emo.v.hi.neu$z_val))`, p `r (printp(lo.emo.v.hi.neu$p.value))`, neutral loads. The same was true for high emotional load ratings and low, Z = `r (printnum(hi.emo.v.lo.neu$z_val))`, p `r (printp(hi.emo.v.lo.neu$p.value))`, and high, Z = `r (printnum(hi.emo.v.hi.neu$z_val))`, p `r (printp(hi.emo.v.hi.neu$p.value))`, neutral loads. However, there was no effect of load. That is, the comparisons between low and high load ratings for both emotional, Z = `r (printnum(lo.emo.v.hi.emo$z_val))`, p = `r (printp(lo.emo.v.hi.emo$p.value))`, and neutral, Z = `r (printnum(lo.neu.v.hi.neu$z_val))`, p = `r (printp(lo.neu.v.hi.neu$p.value))`, load ratings were not significantly different [^2]. 
<!-- double check that this is true for the repeated measures ANOVA analysis too -->
``` {r plot figure 1, include = TRUE}
friedman.data$Condition <- factor(friedman.data$Condition, levels = c("lo.emo.sur_rate", "hi.emo.sur_rate",
                                                                      "lo.neu.sur_rate", "hi.neu.sur_rate"))
friedman.data$Condition <- recode(friedman.data$Condition, "lo.emo.sur_rate" = "Low Emotional", "hi.emo.sur_rate" = "High Emotional",
                                                            "lo.neu.sur_rate" = "Low Neutral", "hi.neu.sur_rate" = "High Neutral")
friedman.data$`Percent Negative Ratings` <- friedman.data$`Percent Negative Ratings` * 100
ggplot(friedman.data, aes(Condition, `Percent Negative Ratings`, fill = Condition)) +
  geom_bar(stat = "summary", fun.y = "mean") +
  scale_fill_manual(values = c("#0d7378", "#21e1eb", "#498526", "#65e01d")) + 
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .1) +
  expand_limits(y=c(0, 100)) +
  theme_apa() +
  theme(axis.text.x=element_blank()) 
  
```

[^2]: These results are qualitatively the same when analyzing these data with a repeated measures ANOVA. 

``` {r MAD, include = FALSE}
###  MAD analyses ###
### check for normality ###
shapiro.test(data$lo.emo.sur_MAD) # not normal (p = .024)
shapiro.test(data$hi.emo.sur_MAD) # barely normal (p = .09)
shapiro.test(data$lo.neu.sur_MAD) # normal
shapiro.test(data$hi.neu.sur_MAD) # normal

MAD.long <- gather(data, key = "Condition", value = "MAD",
                       lo.emo.sur_MAD, hi.emo.sur_MAD, lo.neu.sur_MAD, hi.neu.sur_MAD)
MAD.long$load <- ifelse(MAD.long$Condition == "lo.emo.sur_MAD", "Low",
                            ifelse(MAD.long$Condition == "lo.neu.sur_MAD", "Low", "High"))
MAD.long$type <- ifelse(MAD.long$Condition == "lo.emo.sur_MAD", "Emo",
                            ifelse(MAD.long$Condition == "hi.emo.sur_MAD", "Emo", "Neu"))

MAD.anova <- aov(MAD ~ load * type, data = MAD.long)
summary.aov(MAD.anova)
MAD.anova <- tidy(MAD.anova)
```
Next, we assessed differences in maximum absolute deviation (MD) across the working memory trial conditions. While one of the conditions, low emotional MD, was not normally distributed (p = .024), all other conditions were normally distributed and repeated-measures ANOVA was used to analyze the MDs across conditions. There was a significant effect of load, F(`r printnum(MAD.anova$df[which(MAD.anova$term == "load")])`,`r printnum(MAD.anova$df[which(MAD.anova$term == "Residuals")])`) = `r printnum(MAD.anova$statistic[which(MAD.anova$term == "load")])`, p = `r printp(MAD.anova$p.value[which(MAD.anova$term == "load")])`, such that MDs under high load were larger than trials with low load. There was no significant effect of domain on MDs, F(`r printnum(MAD.anova$df[which(MAD.anova$term == "type")])` `r printnum(MAD.anova$df[which(MAD.anova$term == "Residuals")])`) = `r printnum(MAD.anova$statistic[which(MAD.anova$term == "type")])`, p = `r printp(MAD.anova$p.value[which(MAD.anova$term == "type")])`, nor an interaction of load by domain, F(`r printnum(MAD.anova$df[which(MAD.anova$term == "load:type")])` `r printnum(MAD.anova$df[which(MAD.anova$term == "Residuals")])`) = `r printnum(MAD.anova$statistic[which(MAD.anova$term == "load:type")])`, p = `r printp(MAD.anova$p.value[which(MAD.anova$term == "load:type")])`. 
``` {r MAD plot, include = TRUE}
MAD.long$Condition <- factor(MAD.long$Condition, levels = c("lo.emo.sur_MAD", "hi.emo.sur_MAD",
                                                                      "lo.neu.sur_MAD", "hi.neu.sur_MAD"))
MAD.long$Condition <- recode(MAD.long$Condition, "lo.emo.sur_MAD" = "Low Emotional", "hi.emo.sur_MAD" = "High Emotional",
                                                            "lo.neu.sur_MAD" = "Low Neutral", "hi.neu.sur_MAD" = "High Neutral")
ggplot(MAD.long, aes(Condition, MAD, fill = Condition)) +
  geom_bar(stat = "summary", fun.y = "mean") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .1) +
  scale_fill_manual(values = c("#0d7378", "#21e1eb", "#498526", "#65e01d")) + 
  theme_apa() +
  theme(axis.text.x=element_blank()) 

```
``` {r MAD map, include = FALSE}
suppressPackageStartupMessages(library(mousetrap)) 
# source MADFigure.R ??? 

```

# Discussion
The effect of high vs. low load is still not apparent in these data, just like Mattek et al. 2016. An alternative explanation is that the high load manipulation is not sufficiently difficult to recruit the targeted cognitive resources; however, future work will be needed to better test this alternative. 

Increased working memory demands (i.e., a higher cognitive load) do not always result in poorer performance on concurrent tasks. For instance Baddeley -[@baddeley_working_1986] reported that increasing load by adding digits to a rehearsed number did not affect accuracy on a concurrent verbal reasoning task--instead, there was an increase in the latency of response, a potential interference effect that did not alter overall accuracy. 

Previous work has shown that more positive interpretations of surprised faces are related to slower RTs. Our working hypothesis suggests that this delayed reaction is a result of deliberation and slower, top-down cognitive processing. It is interesting to note that, at least in these data, there is no such difference observed between the neutral and emotional WM trials, *even though* the emotional WM trials are overall more negative. Future work should tease apart why this may be. For instance, ... 

Future work should consider whether the representations of these emotional images in AWM (Reuter-Lorenz), or 

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
